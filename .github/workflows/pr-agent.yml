name: PR Agent with Chutes AI

on:
  pull_request:
    types: [opened, reopened, ready_for_review]
  issue_comment:
    types: [created]

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  pr_agent_job:
    # Do not run on PRs created by bots
    if: ${{ github.event.sender.type != 'Bot' }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Test Chutes AI Connection
        run: |
          echo "Testing connectivity to Chutes AI..."
          echo "1. Testing models endpoint..."
          curl -f -s https://llm.chutes.ai/v1/models \
            -H "Authorization: Bearer ${{ secrets.CHUTES_AI_API_KEY }}" \
            || echo "‚ùå Models endpoint failed"
          
          echo "2. Testing completion endpoint..."
          curl -X POST https://llm.chutes.ai/v1/chat/completions \
            -H "Authorization: Bearer ${{ secrets.CHUTES_AI_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{
              "model": "zai-org/GLM-4.5-FP8",
              "messages": [{"role": "user", "content": "test"}],
              "max_tokens": 1
            }' --fail -v

      - name: PR Agent action step
        id: pragent
        uses: Codium-ai/pr-agent@main
        env:
          # This is the standard GitHub token, required for the agent to interact with the PR
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          # Your Chutes AI configuration (hardcoded)
          OPENAI__API_BASE: "https://llm.chutes.ai/v1"
          OPENAI__KEY: ${{ secrets.CHUTES_AI_API_KEY }}
          CONFIG__MODEL: "openai/zai-org/GLM-4.5-FP8"
          CONFIG__FALLBACK_MODELS: '["openai/moonshotai/Kimi-K2-Instruct-0905"]'
          
          # Timeout configuration to fix LiteLLM aiohttp connection errors
          REQUEST_TIMEOUT: "60"                    # Global timeout for all requests
          OPENAI_TIMEOUT: "60"                     # OpenAI client specific timeout
          OPENAI_MAX_RETRIES: "3"                  # Max retries for failed requests
          USE_AIOHTTP_TRANSPORT: "True"            # Enable improved aiohttp transport
          
          # For custom models, you must specify the maximum token limit
          CONFIG__CUSTOM_MODEL_MAX_TOKENS: 128000
          
          # --- Tell the agent what to do automatically on a new PR ---
          # Run the '/review' tool automatically on new PRs
          github_action_config.auto_review: true

          # Run the '/describe' tool automatically on new PRs
          github_action_config.auto_describe: true

          # Run the '/improve' tool automatically on new PRs
          github_action_config.auto_improve: true 